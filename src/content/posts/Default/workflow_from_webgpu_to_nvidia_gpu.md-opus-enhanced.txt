# Enhanced WebGPU to NVIDIA GPU Workflow

## CPU-Side Pipeline

### 1. WebGPU API Call in Renderer Process

```
Application JavaScript
    ↓
device.queue.submit([commandBuffer])
```

**Detailed breakdown:**
- The `GPUQueue.submit()` call accepts an array of `GPUCommandBuffer` objects
- Each command buffer contains pre-recorded GPU commands (render passes, compute passes, copy operations)
- The WebGPU implementation (in Blink) performs final validation:
  - Resource usage validation (no simultaneous read/write conflicts)
  - Buffer/texture state tracking
  - Bind group compatibility verification
- Command buffers are marked as "submitted" and become immutable
- The call is asynchronous from JavaScript's perspective but synchronous at the API boundary

---

### 2. Mojo IPC to GPU Process

```
Renderer Process (Blink/WebGPU frontend)
    ↓ Mojo IPC
GPU Process (Dawn backend)
```

**Detailed breakdown:**

**Serialization phase:**
- Commands are serialized into Dawn's wire format (`dawn_wire`)
- Wire protocol uses a client-server architecture:
  - `DawnWireClient` in renderer process
  - `DawnWireServer` in GPU process
- Object handles (buffers, textures, pipelines) are translated to wire IDs
- Large data transfers (buffer writes) may use shared memory segments instead of copying

**IPC transport:**
- Mojo message pipes provide the transport layer
- Messages are queued in the GPU process's command buffer service
- Flow control prevents renderer from overwhelming GPU process
- Security boundary: GPU process validates all incoming commands (defense against compromised renderer)

**Why bypass compositor:**
- WebGPU commands go directly to GPU process, not through `cc::LayerTreeHost`
- No rasterization or compositing overhead for compute workloads
- For rendering, final swapchain presentation integrates with compositor via `SharedImage`

---

### 3. Dawn Command Processing

```
DawnWireServer (deserialize)
    ↓
Dawn Device/Queue objects
    ↓
Backend translation (Vulkan/Metal/D3D12)
```

**Detailed breakdown:**

**Wire deserialization:**
- `DawnWireServer` reconstructs command structure from wire format
- Object ID → native object handle resolution
- Injection point for GPU process-side validation

**Command buffer replay:**
- Dawn maintains internal command recording state
- Commands are translated to backend-specific equivalents:

| WebGPU Command | Vulkan Equivalent |
|----------------|-------------------|
| `beginRenderPass` | `vkCmdBeginRenderPass` |
| `setPipeline` | `vkCmdBindPipeline` |
| `setBindGroup` | `vkCmdBindDescriptorSets` |
| `draw` | `vkCmdDraw` |
| `dispatchWorkgroups` | `vkCmdDispatch` |

**Resource barrier insertion:**
- Dawn automatically inserts pipeline barriers
- Tracks resource states (e.g., `VK_IMAGE_LAYOUT_*` transitions)
- Ensures proper synchronization between passes

---

### 4. Tint Shader Compilation

```
WGSL source
    ↓ Tint frontend (parse + validate)
Tint IR (internal representation)
    ↓ Tint backend
Target IR (SPIR-V / AIR / DXIL)
```

**Detailed breakdown:**

**Frontend (WGSL → Tint IR):**
- Lexer/parser generates AST
- Type inference and checking
- Semantic analysis:
  - Built-in function resolution
  - Address space validation (`uniform`, `storage`, `workgroup`)
  - Binding decoration validation (`@group`, `@binding`)
- Transform passes:
  - Array length clamping (bounds checking)
  - Robustness transforms (prevent OOB access)
  - Workgroup uniform analysis

**Backend (Tint IR → Target):**

For **SPIR-V** (Vulkan/OpenGL):
```
Tint IR
    ↓ SPIR-V writer
SPIR-V binary (logical addressing mode)
    ↓ (optional) spirv-opt
Optimized SPIR-V
```
- Output conforms to Vulkan's SPIR-V environment
- Includes `OpCapability Shader`, required extensions
- Descriptor bindings mapped to SPIR-V decoration

For **AIR** (Metal on macOS/iOS):
```
Tint IR
    ↓ MSL writer
Metal Shading Language source
    ↓ Metal compiler (in driver)
AIR bitcode
```

For **DXIL** (D3D12 on Windows):
```
Tint IR
    ↓ HLSL writer
HLSL source
    ↓ DXC (DirectX Shader Compiler)
DXIL bitcode
```

**Caching:**
- Dawn maintains a pipeline cache (`GPUPipelineCache`)
- Hashes: WGSL source + pipeline layout + render state
- Compiled shaders stored for reuse across sessions

---

### 5. Vulkan Runtime Layer (Linux/Windows Vulkan path)

```
SPIR-V binary
    ↓
Vulkan Loader (libvulkan.so)
    ↓
Validation Layers (optional, debug only)
    ↓
NVIDIA Vulkan ICD (Installable Client Driver)
```

**Detailed breakdown:**

**Vulkan loader dispatch:**
- `vkCreateShaderModule` receives SPIR-V bytecode
- Loader dispatches to appropriate ICD
- Instance/device function pointer trampolines

**Driver ingestion:**
- NVIDIA's `libGLX_nvidia.so` / `nvoglv64.dll` receives SPIR-V
- Internal representation built from SPIR-V
- May perform driver-level optimizations before PTX

---

### 6. NVIDIA Kernel Driver Compilation

```
SPIR-V / PTX
    ↓ nvidia-uvm / nvidia.ko (kernel module)
NVLink/PCIe DMA setup
    ↓ Firmware-assisted compilation
SASS (machine code)
```

**Detailed breakdown:**

**User-mode driver (UMD) processing:**
- Located in `libnvidia-glcore.so` (Linux) or `nvd3dumx.dll` (Windows)
- SPIR-V → PTX translation (if not already PTX)
- PTX optimization passes:
  - Register allocation hints
  - Instruction scheduling
  - Memory access coalescing analysis

**PTX → SASS compilation:**
- JIT compilation by driver's embedded `ptxas` equivalent
- Target-specific optimization based on GPU architecture (e.g., `sm_89` for Ada Lovelace)
- Output is **SASS** (Shader ASSembly), the native ISA

**SASS optimization examples:**
```
; PTX (intermediate)
wmma.load.a.sync.aligned.m16n16k16.row.f16 {r0,r1,r2,r3}, [addr]
wmma.mma.sync.aligned.m16n16k16.row.row.f16.f16 {d0..d3}, {a0..a3}, {b0..b3}, {c0..c3}

; SASS (machine code) - approximate, actual encoding proprietary
HMMA.16816.F16 R0, R4, R8, R12 ;  // Tensor Core instruction
```

**Compiled shader caching:**
- Driver maintains on-disk shader cache (`~/.nv/ComputeCache` on Linux)
- Key: hash of PTX + GPU architecture + driver version
- Avoids recompilation on subsequent runs

---

### 7. Command Buffer Submission to Hardware

```
SASS binary + command stream
    ↓ ioctl() to nvidia.ko
Kernel-mode driver (KMD)
    ↓ GPU channel push
MMIO / BAR writes to GPU
```

**Detailed breakdown:**

**Push buffer construction:**
- User-mode driver constructs GPU command buffer ("push buffer")
- Commands encoded as GPU-specific method/data pairs
- Method IDs correspond to GPU engine registers

**Example push buffer structure:**
```
[Header]
  - Channel ID
  - Submission fence value
[Commands]
  - SET_SHADER_PROGRAM: address of SASS binary
  - SET_CONSTANT_BUFFER: address of uniform data
  - SET_BINDING_TABLE: descriptor addresses
  - DISPATCH: grid dimensions (for compute)
  - LAUNCH: trigger execution
[Fence]
  - RELEASE_SEMAPHORE: signal completion
```

**Kernel interaction:**
- `ioctl(fd, NVOS_IOCTL_SUBMIT, ...)` submits push buffer
- Kernel module (`nvidia.ko`) validates submission
- DMA engine transfers push buffer to GPU-visible memory
- GPU channel doorbell written via MMIO

---

## GPU-Side Execution

### 8. GPU System Processor (GSP)

```
Push buffer arrives via PCIe/NVLink
    ↓
GSP firmware
    ↓
Command validation + routing
```

**Detailed breakdown:**

**GSP architecture (introduced Ada Lovelace / Hopper):**
- RISC-V based microcontroller
- Runs real-time operating system (RTOS)
- Offloads CPU driver work to GPU itself

**GSP responsibilities:**
- Security: validates command stream integrity
- Resource management: VRAM allocation, context switching
- Power management: DVFS (Dynamic Voltage Frequency Scaling)
- Error handling: ECC errors, page faults
- Telemetry: performance counters, thermal monitoring

**Pre-Ada GPUs:**
- These functions handled by CPU-side driver + simpler GPU firmware
- GSP consolidates into dedicated processor

---

### 9. Host Interface / Front End

```
GSP validated commands
    ↓
Host Interface unit
    ↓
Front End (FE) engine
```

**Detailed breakdown:**

**Host Interface:**
- PCIe/NVLink endpoint controller
- DMA engines for data transfer
- Manages multiple GPU channels (contexts)
- Channel scheduling: round-robin with priority

**Front End:**
- Parses push buffer method stream
- Routes commands to appropriate engines:
  - Graphics: primitive assembly, rasterization setup
  - Compute: kernel launch
  - Copy: DMA engines
  - Video: NVENC/NVDEC

---

### 10. GPU Command Processor

```
Parsed commands from FE
    ↓
Command Processor (compute path)
    ↓
Kernel launch setup
```

**Detailed breakdown:**

**Command types handled:**
- State updates (shader program, bindings, render targets)
- Synchronization (barriers, events)
- Execution commands (draw calls, compute dispatches)

**For compute dispatch (`dispatchWorkgroups`):**
- Extracts grid dimensions (workgroup count X×Y×Z)
- Extracts block dimensions (from shader metadata)
- Computes total thread count
- Passes to GigaThread Engine for scheduling

---

### 11. GigaThread Engine

```
Kernel launch command
    ↓
GigaThread Engine
    ↓
CTA (Cooperative Thread Array) scheduling
```

**Detailed breakdown:**

**Role:**
- Global work distributor for entire GPU
- Manages CTA (block) scheduling across all GPCs
- Load balancing across SMs

**CTA scheduling algorithm:**
- Input: Grid size (number of CTAs), CTA resource requirements
- Constraints per SM:
  - Max CTAs (typically 16-32)
  - Max warps (48-64 depending on arch)
  - Shared memory limit (48-164 KB)
  - Register file limit (65536 registers)
- Output: CTA→SM assignment

**Scheduling modes:**
- **Greedy fill**: Pack CTAs into SMs until full
- **Round-robin**: Distribute evenly for latency hiding
- **Persistence**: For cooperative kernels needing cross-CTA sync

**Dynamic parallelism:**
- Child kernels launched from GPU code
- GigaThread Engine handles nested scheduling

---

### 12. Graphics Processing Cluster (GPC)

```
CTAs assigned from GigaThread
    ↓
GPC (contains multiple SMs + shared units)
    ↓
SM-level dispatch
```

**Detailed breakdown:**

**GPC structure (e.g., AD102 - RTX 4090):**
```
GPC (x12 total)
├── Raster Engine (1 per GPC)
├── ROP partition (Render Output Units)
└── TPC (Texture Processing Cluster) × 6
    └── SM × 2 per TPC
```

**For compute workloads:**
- Raster engine idle
- ROPs used only for atomics/output
- TPCs route CTAs to their SMs

**Shared GPC resources:**
- L1.5 texture cache (shared across TPCs)
- Raster engine (graphics only)
- Geometry processing (graphics only)

---

### 13. Streaming Multiprocessor (SM)

```
CTAs assigned to SM
    ↓
Warp scheduling
    ↓
Execution units
```

**Detailed breakdown:**

**SM structure (Ada Lovelace SM):**
```
SM
├── Warp Schedulers × 4
│   └── Dispatch units × 1 each
├── Register File (65536 × 32-bit)
├── Processing blocks × 4
│   ├── FP32 units × 16
│   ├── INT32 units × 16
│   ├── FP64 units × 1 (varies by SKU)
│   ├── Tensor Core × 1
│   └── Load/Store units × 4
├── Special Function Units × 4
├── Shared Memory (up to 100KB configurable)
├── L1 Cache (up to 128KB configurable)
└── Texture units × 4
```

**CTA to warp mapping:**
- CTA declared with block size (e.g., 256 threads)
- SM divides into warps: 256 / 32 = 8 warps
- Each warp assigned to warp scheduler in round-robin

**Warp scheduler operation (per cycle):**
1. Check eligible warps (not stalled)
2. Select warp via scheduling policy (GTO, LRR, etc.)
3. Issue instruction from selected warp
4. Update scoreboard for dependencies

**Shared memory (SMEM):**
- Fast (single-cycle latency), on-chip
- Shared across all warps in CTA
- Used for cooperative algorithms (reductions, matrix tiles)
- Bank conflicts cause serialization

---

### 14. Warp Execution

```
Warp selected by scheduler
    ↓
Instruction fetch
    ↓
Decode
    ↓
Execute on SIMT lanes
```

**Detailed breakdown:**

**Warp structure:**
- 32 threads executing in lockstep (SIMT)
- Single Program Counter (PC) per warp
- Per-thread predicate mask for divergence

**Instruction pipeline:**
```
Cycle 0: Instruction fetch (I-cache lookup)
Cycle 1: Decode (determine operands, execution unit)
Cycle 2: Operand collection (register file read)
Cycle 3: Execute (ALU, memory, etc.)
Cycle 4+: Writeback (variable latency)
```

**Divergence handling:**
```wgsl
if (thread_id < 16) {
    // Path A
} else {
    // Path B
}
```
- Warp executes both paths sequentially
- Predicate mask disables non-participating lanes
- Reconvergence at control flow join point

**Memory access coalescing:**
- 32 threads issue memory requests
- Hardware coalesces to minimize transactions
- Ideal: 32 consecutive 4-byte accesses → 1 × 128B transaction
- Worst: 32 scattered accesses → 32 × 32B transactions

---

### 15. Execution Units (CUDA / Tensor Cores)

```
Decoded instruction + operands
    ↓
Functional unit execution
```

**CUDA Core operations:**

| Instruction Type | Unit | Throughput (per SM per cycle) |
|------------------|------|-------------------------------|
| FP32 add/mul/fma | FP32 | 128 ops |
| INT32 add/mul | INT32 | 64 ops |
| FP16 (packed) | FP32 | 256 ops |
| FP64 | FP64 | 2-4 ops (varies) |
| Special (sin, exp) | SFU | 16 ops |

**Tensor Core operations:**

```
HMMA (Half-precision Matrix Multiply-Accumulate)
    - Input: A[16×16] FP16, B[16×16] FP16
    - Accumulator: C[16×16] FP16/FP32
    - Output: D = A × B + C
    - Throughput: 512 FP16 ops per cycle per TC
```

**Tensor Core instruction mapping:**
```
; WGSL / SPIR-V compute shader using matrix extensions
; After driver compilation:

; PTX
wmma.load.a.sync.aligned.row.m16n16k16.f16 {r0-r7}, [ptrA]
wmma.load.b.sync.aligned.col.m16n16k16.f16 {r8-r15}, [ptrB]
wmma.mma.sync.aligned.row.col.m16n16k16.f16.f16 {r16-r23}, {r0-r7}, {r8-r15}, {r24-r31}
wmma.store.d.sync.aligned.row.m16n16k16.f16 [ptrD], {r16-r23}

; SASS (approximate, actual encoding secret)
HMMA.16816.F16.F16 R16, R0, R8, R24 ;
```

---

### 16. Memory Hierarchy Access

```
Load/Store instructions
    ↓
Address generation
    ↓
Memory hierarchy traversal
```

**Memory hierarchy (latency in cycles):**

```
Register file:     0 cycles (operand access)
    ↓
Shared memory:     ~20-30 cycles
    ↓
L1 cache:          ~30-40 cycles
    ↓
L2 cache:          ~200-300 cycles
    ↓
VRAM (HBM3/GDDR6): ~400-600 cycles
```

**L1/Shared memory configuration (Ada):**
- Total: 128KB per SM
- Configurable split: 0/128, 32/96, 64/64, 96/32, 128/0 KB

**L2 cache:**
- Shared across all SMs
- Size: 48-96 MB (varies by SKU)
- Bandwidth: ~6 TB/s (AD102)

**Global memory access pattern:**
```
Thread 0:  addr = base + 0
Thread 1:  addr = base + 4
...
Thread 31: addr = base + 124

→ Coalesced into single 128B transaction
```

---

### 17. Writeback and Completion

```
Execution complete
    ↓
Register writeback
    ↓
Memory writeback (if store)
    ↓
CTA completion tracking
```

**Detailed breakdown:**

**Register writeback:**
- Results written to physical registers
- Scoreboard cleared, allowing dependent instructions

**Memory store handling:**
- Stores buffered in per-SM write buffer
- Coalesced and flushed to L2
- Atomics may require L2 round-trip

**CTA completion:**
- When all warps complete, CTA retires
- Shared memory freed for new CTA
- GigaThread Engine notified

---

### 18. Synchronization and Fence

```
All CTAs complete
    ↓
L2 cache flush (if needed)
    ↓
Semaphore release
    ↓
Interrupt to CPU
```

**Detailed breakdown:**

**GPU-side synchronization:**
- `__syncthreads()` → barrier within CTA
- `__threadfence()` → memory fence
- Grid completion → engine fence

**CPU notification:**
- GPU writes completion fence value to system memory
- MSI-X interrupt to CPU (if configured)
- CPU polls fence or wakes from interrupt

**Vulkan synchronization mapping:**
- `vkQueueSubmit` fence → GPU semaphore release
- `vkWaitForFences` → CPU polls/waits on fence value

---

## Complete Pipeline Visualization

```
┌─────────────────────────────────────────────────────────────────┐
│                        CPU SIDE                                  │
├─────────────────────────────────────────────────────────────────┤
│  JS: device.queue.submit()                                       │
│         ↓                                                        │
│  Blink WebGPU → Mojo IPC → GPU Process                          │
│         ↓                                                        │
│  Dawn: WGSL → Tint → SPIR-V                                     │
│         ↓                                                        │
│  Vulkan: vkCreateShaderModule + vkQueueSubmit                   │
│         ↓                                                        │
│  NVIDIA UMD: SPIR-V → PTX → SASS                                │
│         ↓                                                        │
│  KMD: Push buffer → PCIe/NVLink                                 │
└─────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────┐
│                        GPU SIDE                                  │
├─────────────────────────────────────────────────────────────────┤
│  GSP: Security validation, resource management                   │
│         ↓                                                        │
│  Host Interface → Front End → Command Processor                 │
│         ↓                                                        │
│  GigaThread Engine: CTA distribution                            │
│         ↓                                                        │
│  GPC → TPC → SM                                                 │
│         ↓                                                        │
│  Warp Scheduler: Instruction issue                              │
│         ↓                                                        │
│  CUDA/Tensor Cores: Execute SASS                                │
│         ↓                                                        │
│  Memory: Registers → SMEM → L1 → L2 → VRAM                      │
│         ↓                                                        │
│  Completion: Fence → Interrupt → CPU                            │
└─────────────────────────────────────────────────────────────────┘
```

---

## Latency Breakdown (Approximate)

| Stage | Typical Latency |
|-------|-----------------|
| JS → Mojo IPC | ~10-50 μs |
| Dawn command processing | ~20-100 μs |
| Tint compilation (cold) | ~1-50 ms |
| Driver compilation (cold) | ~10-500 ms |
| Push buffer submission | ~5-20 μs |
| PCIe round-trip | ~1-5 μs |
| GPU execution | Varies widely |
| Fence completion | ~1-10 μs |

**Note:** Shader compilation is heavily cached; warm paths see sub-millisecond total submission latency.