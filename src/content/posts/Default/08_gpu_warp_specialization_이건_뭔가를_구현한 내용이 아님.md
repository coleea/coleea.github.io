---
title: Warp Specialzation
published: 2025-12-19
description: ""
tags: []
category: Default
draft: false
---

# Warp Specialzation 

- 정의 : Warp Specialzation 은 말 그대로 각 워프를 전문화 한다는 뜻이다
- 어셈블리 공장처럼 A워프는 A작업만 하고 B워프는 B작업만 하는 식으로 각각의 워프가 범용 업무가 아닌 할당된 업무만 수행한다
- 이런 개념은 2022년 엔비디아에서 공개한 호퍼(Hopper) 아키텍처부터 두드러졌다
- 그러므로 호퍼 아키텍처에 무슨 변화가 있었는지를 생각하면 왜 이런 개념이 생겼는지 알 수 있다
- 호퍼 아키텍처는 SM과 SM간의 다이렉트 데이터 전송이 가능한 전송 계층이 추가되었다 (Direct SM-to-SM communication)

![](/images/gpu_nvidia/hopper-sm-to-sm-network.jpg)
(이미지 출처 : TODO )

- 이 전송 계층을 이용하면 L2캐시 또는 전역 메모리(Global Memory, GMEM)에 접근할 필요 없이 다른 SM의 Shared Local Memory에 저장된 데이터에 빠르게 억세스할 수 있다. 이를 분산 공유 메모리 (Distributed Shared Memory)라고 부른다.
- 다시 말해 이전까지는 단일 SM이 제공하는 공유메모리(Shared Local Memory, 이하 SLM)에만 의존하여 수치연산을 하는것이 일반적인 방식이었지만 이제는 2개 이상의 SM을 하나로 묶어 공유메모리의 크기를 더 늘린 상태로 수치연산을 수행해도 전역메모리 접근에 의한 속도저하를 걱정하지 않아도 된다는 것이다
- 그래서 많게는 8개의 SM을 하나의 연산단위로 묶어서 행렬곱을 수행할 수도 있다. 이런 연산법은 호퍼(Hopper) 아키텍처 이전에는 생각할수도 없는 신박한 발상인 것이다
- 8개의 SM을 쓰면 공유메모리의 크기도 8배로 늘어난다. 이 대용량 공유메모리를 효과적으로 사용할 수 있는 방법이 무엇인지 연구하다가 개발자들이 정착한 방법이 바로 워프 전문화(Warp Specialzation) 이다. 
- "이게 대용량 공유메모리를 쓰는 이론상 가장 좋은 방법이다" 라는 증거같은건 없지만 그래도 정답에 가장 근접한 것임은 분명하고 실제로 속도 향상이 크게 이루어졌다
- 이 방법론의 핵심은 여러개의 버퍼를 만들어서 나중에 연산할 데이터까지 한번에 읽어오는 것이다
- 하나의 워프(Warp)에서 텐서 코어를 사용할 때 다른 워프는 전역메모리에서 다음번 연산에 필요한 타일 데이터를 가져온다. 
- 이렇게 텐서코어가 연산중일 때 다른 미리 타일 데이터를 가져오면 텐서코어 연산이 끝나자 마자 다른 타일을 연산할 수 있다. 이렇게 하면 텐서코어가 유휴시간이 없이 계속 연산하게 하는것이 가능하다
- 즉 워프 전문화의 최종 목적은 2가지인데 가장 중요한 것은 텐서코어를 쉬지않고 연산하게 하는 것이다. 그리고 그 다음으로 중요한 것은 메모리 대역폭을 쉬지않고 모두 사용하는 것이다.
- 이렇게 하면 다음 사이클에 연산할 타일 데이터가 공유메모리(SLM)에 로드되므로 대충 생각해봐도 일반 연산대비 2배의 메모리가 필요하다.
- 하지만 메타 연구원인 Hongtao Yu가 수행한 리서치에 의하면 그는 일반적인 더블 버퍼링 방법이 아닌 트리플 버퍼링 방식을 사용하여 최적화를 수행했다
- 즉 다음 사이클과 다다음 사이클에 필요한 데이터를 공유메모리(SLM)에 로드하는 방식을 선택한 것이다
- 이렇게 하면 한번에 처리할 수 있는 타일의 크기가 그만큼 줄어들지만 그럼에도 불구하고 왜 트리플 버퍼링 방식을 고수한 것인가 
- 전역 메모리에서 데이터를 가져오는 과정에서 텐서코어 연산이 완료되기 이전에 데이터를 가져온다는 보장이 없기 때문이다
- 그래서 트리플 버퍼링 방식을 선택한 것인데 아래 사진을 참고하라

![](/images/gpu_nvidia/hopper_warp_specialization.png)
(이미지 출처 : https://www.youtube.com/watch?v=QvF2z7P-cgU)

- 위 그림에서 warp 1,2,3,4는 데이터 로드만을 담당하는 생산자 워프이고, warp 5,6,7,8은 로드된 타일을 행렬곱하는 행렬곱 전용 워프의 그룹이다. 
- warp 9,10,11,12도 마찬가지로 행렬곱 전용 워프의 그룹이다.
- 이 최적화는 호퍼(Hopper) 아키텍처에서 수행되었는데 사진에 보이는 것 처럼 `wgmma` 명령어로 텐서코어 유닛을 사용한 것을 확인할 수 있을 것이다.
- `wgmma`는 Warp-Group Matrix Multiply-Accumulate의 약자인데 행렬곱을 워프(warp)의 그룹 단위로 수행하겠다는 것을 의미한다. 그 그룹이란 4개의 워프인데 4개의 워프인 이유는 SM의 하위 유닛인 프로세싱 블록 (Processing blocks)의 갯수가 4개이기 때문이다

![](/images/gpu_nvidia//h100-sm.png)
(이미지 출처 : TODO )

위 사진에 4개의 공통된 유닛이 보일 것인데 이를 프로세싱 블록 (Processing blocks)이라고 한다. 그리고 각 프로세싱 블록마다 한개의 텐서코어 유닛을 가지고 있다.

즉 4개의 워프를 사용하여 텐서코어 연산을 수행하겠다는 것은 SM내부에 있는 4가지 텐서코어를 동시에 사용하여 행렬곱을 수행하겠다는 것이다. `wgmma` 명령어는 그렇게 수행된다. 

이제 위의 이미지를 다시보면 왜 워프가 4개 단위로 묶였는지를 이해할 수 있을 것이다

## 최적화 결과 

![](/images/gpu_nvidia//hopper_warp_specialization_result.png)
(이미지 출처 : https://www.youtube.com/watch?v=QvF2z7P-cgU)

메타 연구원인 Hongtao Yu가 수행한 워프 전문화의 벤치마크 결과이다. 워프 전문화 전에는 컴퓨트 대역폭이 45.33%였는데 위에 소개한 워프 대역폭을 적용한 결과 대역폭이 69.48%로 최적화 이전대비 24.15% 증가하였다

## 블랙웰 아키텍처에서의 워프 전문화

- 블랙웰은 NVFP4라는 유닛에 기반한 4bit 텐서코어 연산을 지원한다
- 이 4bit 데이터에 기반한 텐서코어 연산은 fp8 연산대비 2배 빠르게 수행된다
- 이 말은 기존에 호퍼(Hopper)아키텍처에서 사용한 트리플 버퍼 만으로는 텐서코어를 쉬지않고 돌릴 수 없다는 뜻이다. 
- 그러므로 블랙웰에서 NVFP4 기반의 텐서코어 연산을 수행할 때 4중버퍼, 5중버퍼등의 전략을 사용하는데 이것이 무슨뜻이냐면 공유메모리(SLM)에 다음 사이클에 사용할 타일, 다다음 사이클에 사용할 타일, 다다다음 사이클에 사용할 타일, 다다다다음 사이클에 사용할 타일을 동시에 로드한다는 뜻이다.
- 다시 말해 아키텍처가 변경되면 이전 아키텍처에서 최고의 효율을 보여줬던 그 알고리즘이 더이상 최고가 아닐수 있다는 것을 의미한다
- 그렇기 때문에 엔비디아 측도 아키텍처가 변경되면 해당 아키텍처에 최적화된 커널을 다시 작성한다
- 가령 CUTLASS 공식 레포지토리인 `https://github.com/NVIDIA/cutlass/tree/main/include/cutlass/gemm/collective` 를 보면 각 아키텍처별로 `warp specialized` 커널이 서로 다르게 구현된 것을 확인할 수 있다.

## 블랙웰 아키텍처의 cta_group=2 설정
- 블랙웰에 `tcgen05`라는 이름의  텐서코어 명령어가 새로 추가되었다
- 이 명령어는 이전 세대의 텐서코어 명령어인 `wgmma`의 업그레이드 버전이다
- 특이한 점은 이 `tcgen05`의 옵션으로 CTA 그룹의 갯수를 설정할 수 있다는 것이다 
- 예를들어 `tcgen05.mma.cta_group::2.kind::tf32`라는 연산자는 CTA 그룹 2개를 사용하여 텐서코어 기반의 행렬곱을 수행하겠다는 것을 의미한다
- CTA는 `Co-operative Thread Array`의 약자인데 다른말로 스레드 블록(thread block)이라고도 한다
- 이 글을 읽는 독자라면 스레드 블록이 처리되는 단위는 SM(Streaming Multiprocessor)라는 것을 들어봤을 것이다
- 그러므로 2개의 CTA를 사용한다는 건 2개의 SM을 사용하겠다는 것과 같은 뜻이다. 
- PTX 명령어 레벨에서 행렬곱에 2개의 SM을 사용하는 것은 엔비디아 아키텍처 역사상 블랙웰이 최초이다.
- 호퍼(Hopper) 아키텍처에서 스레드 블록 클러스터(Thread Block Cluster)라는 개념이 도입되어 여러개의 SM을 하나의 대형 타일로 다루는 전략이 가능하기는 했지만 그건 어디까지나 개발자가 그런 방식으로 프로그래밍 했을 때 가능한 것이었다. 다시말해 명령어 레벨에서 지원하는 것이 아니었다는 것이다. 

---

# 워프 전문화는 생산자 워프와 소비자 워프로 분리된다 
- 전역 메모리에서 데이터를 가져와 공유메모리(SLM)에 저장하는 생산자 워프

